{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pickle as pkl\n",
    "import scipy.sparse as sparse\n",
    "import copy\n",
    "import shutil\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from test_tube import Experiment\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "from CoordAE import CoordAE\n",
    "from MSDScorer import MSDScorer\n",
    "from KLDLoss import KLDLoss\n",
    "from data_utils import CODDataset, BlockDataLoader\n",
    "from test import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bb596/.conda/envs/rdenv/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2ae147a94d70>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 0\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handled in args parse for a py script version\n",
    "\n",
    "n_max = 50\n",
    "dim_node = 35\n",
    "dim_edge = 10\n",
    "nval = 3000\n",
    "ntst = 3000\n",
    "hidden_node_dim = 50\n",
    "dim_f = 100\n",
    "batch_size = 20\n",
    "val_num_samples = 10\n",
    "model_name = 'dl4chem'\n",
    "savepermol = True\n",
    "savepreddir = 'savepreddir'\n",
    "use_val = True\n",
    "mpnn_steps = 5\n",
    "alignment_type = 'kabsch'\n",
    "tol = 1e-5\n",
    "use_X=False\n",
    "use_R=True\n",
    "seed=1334\n",
    "refine_steps=0\n",
    "refine_mom=0.99\n",
    "debug = False\n",
    "useFF = False\n",
    "w_reg = 1e-5\n",
    "log_train_steps=100\n",
    "\n",
    "\n",
    "data_dir = '/home/bb596/rds/hpc-work/dl4chem/'\n",
    "dataset = 'COD'\n",
    "COD_molset_50_path = data_dir + 'COD_molset_50.p'  \n",
    "COD_molvec_50_path = data_dir + 'COD_molvec_50.p'\n",
    "\n",
    "# create directories to store results\n",
    "\n",
    "ckptdir = './checkpoints/'\n",
    "if not os.path.exists(ckptdir):\n",
    "    os.makedirs(ckptdir)\n",
    "    \n",
    "eventdir = './events/'\n",
    "train_eventdir = eventdir.split('/')\n",
    "train_eventdir.insert(-1, 'train')\n",
    "train_eventdir = '/'.join(train_eventdir)\n",
    "\n",
    "valid_eventdir = eventdir.split('/')\n",
    "valid_eventdir.insert(-1, 'valid')\n",
    "valid_eventdir = '/'.join(valid_eventdir)\n",
    "\n",
    "if not os.path.exists(train_eventdir):\n",
    "    os.makedirs(train_eventdir)\n",
    "if not os.path.exists(valid_eventdir):\n",
    "    os.makedirs(valid_eventdir)\n",
    "\n",
    "save_path = os.path.join(ckptdir, model_name + '_model.ckpt')\n",
    "\n",
    "molvec_fname = data_dir + dataset + '_molvec_'+str(n_max)+'.p'\n",
    "molset_fname = data_dir + dataset + '_molset_'+str(n_max)+'.p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "nodes_fname = data_dir + dataset + '_nodes_'+str(n_max)+'.p'\n",
    "D1 = pkl.load(open(nodes_fname,'rb'))\n",
    "\n",
    "masks_fname = data_dir + dataset + '_masks_'+str(n_max)+'.p'\n",
    "D2 = pkl.load(open(masks_fname,'rb'))\n",
    "\n",
    "edges_fname = data_dir + dataset + '_edges_'+str(n_max)+'.p'\n",
    "D3 = pkl.load(open(edges_fname,'rb'))\n",
    "\n",
    "dist_mats_fname = data_dir + dataset + '_dist_mats_'+str(n_max)+'.p'\n",
    "D4 = pkl.load(open(dist_mats_fname,'rb'))\n",
    "\n",
    "positions_fname = data_dir + dataset + '_positions_'+str(n_max)+'.p'\n",
    "D5 = pkl.load(open(positions_fname,'rb'))\n",
    "\n",
    "#[D1, D2, D3, D4, D5] = pkl.load(open(molvec_fname,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::: num train samples is \n",
      "(60663, 50, 35) (60663, 50, 50, 10)\n"
     ]
    }
   ],
   "source": [
    "D1 = D1.todense()\n",
    "D2 = D2.todense()\n",
    "D3 = D3.todense()\n",
    "\n",
    "ntrn = len(D5)-nval-ntst\n",
    "\n",
    "[molsup, molsmi] = pkl.load(open(molset_fname,'rb'))\n",
    "\n",
    "D1_trn = D1[:ntrn]\n",
    "D2_trn = D2[:ntrn]\n",
    "D3_trn = D3[:ntrn]\n",
    "D4_trn = D4[:ntrn]\n",
    "D5_trn = D5[:ntrn]\n",
    "molsup_trn = molsup[:ntrn]\n",
    "D1_val = D1[ntrn:ntrn+nval]\n",
    "D2_val = D2[ntrn:ntrn+nval]\n",
    "D3_val = D3[ntrn:ntrn+nval]\n",
    "D4_val = D4[ntrn:ntrn+nval]\n",
    "D5_val = D5[ntrn:ntrn+nval]\n",
    "molsup_val = molsup[ntrn:ntrn+nval]\n",
    "D1_tst = D1[ntrn+nval:ntrn+nval+ntst]\n",
    "D2_tst = D2[ntrn+nval:ntrn+nval+ntst]\n",
    "D3_tst = D3[ntrn+nval:ntrn+nval+ntst]\n",
    "D4_tst = D4[ntrn+nval:ntrn+nval+ntst]\n",
    "D5_tst = D5[ntrn+nval:ntrn+nval+ntst]\n",
    "molsup_tst = molsup[ntrn+nval:ntrn+nval+ntst]\n",
    "print ('::: num train samples is ')\n",
    "print(D1_trn.shape, D3_trn.shape)\n",
    "\n",
    "tm_trn, tm_val, tm_tst = None, None, None\n",
    "\n",
    "del D1, D2, D3, D4, D5, molsup\n",
    "\n",
    "if savepermol:\n",
    "    savepreddir = os.path.join(savepreddir, dataset, \"_val_\" if use_val else \"_test_\")\n",
    "    if not os.path.exists(savepreddir):\n",
    "        os.makedirs(savepreddir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CODDataset(D1_trn, D2_trn, D3_trn, D4_trn, D5_trn)\n",
    "val_dataset = CODDataset(D1_val, D2_val, D3_val, D4_val, D5_val)\n",
    "test_dataset = CODDataset(D1_tst, D2_tst, D3_tst, D4_tst, D5_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Subset(train_dataset, range(100))\n",
    "val_dataset = Subset(val_dataset, range(100))\n",
    "test_dataset = Subset(test_dataset, range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = BlockDataLoader(train_dataset, batch_size, block_size=40)\n",
    "val_num_samples = 2\n",
    "val_batch_size = batch_size // val_num_samples\n",
    "val_dataloader = BlockDataLoader(val_dataset, val_batch_size, block_size=40, shuffle=False)\n",
    "test_dataloader = BlockDataLoader(test_dataset, batch_size, block_size=40, shuffle=False)\n",
    "\n",
    "# train_dataloader = BlockDataLoader(train_dataset, batch_size)\n",
    "# val_dataloader = BlockDataLoader(val_dataset, batch_size)\n",
    "# test_dataloader = BlockDataLoader(test_dataset, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::: start training\n",
      "Train batch number0\n",
      "Train batch number1\n",
      "Train batch number2\n",
      "Train batch number3\n",
      "Train batch number4\n",
      "[[89.88261 51.01035 38.78281 89.4552 ]\n",
      " [82.86212 42.50543 40.26245 94.24034]\n",
      " [73.13549 38.65865 34.3964  80.43465]\n",
      " [98.10341 61.22443 36.79044 88.53731]\n",
      " [80.47719 43.50877 36.87861 89.79737]]\n",
      "testing model...\n",
      "Test batch number0\n",
      "Test batch number1\n",
      "Test batch number2\n",
      "Test batch number3\n",
      "Test batch number4\n",
      "Test batch number5\n",
      "Test batch number6\n",
      "Test batch number7\n",
      "Test batch number8\n",
      "Test batch number9\n",
      "val scores: mean is 3.730968291700299 , std is 0.00040039023999013045\n",
      "::: training epoch id 0 :: --- val mean=3.730968291700299 , std=0.00040039023999013045 ; --- best val mean=3.730968291700299 , std=0.00040039023999013045 \n",
      "Train batch number0\n",
      "Train batch number1\n",
      "Train batch number2\n",
      "Train batch number3\n",
      "Train batch number4\n",
      "[[90.14711 51.73508 38.31546 96.55521]\n",
      " [85.61289 53.60134 31.92986 81.6843 ]\n",
      " [82.36712 45.92783 36.34353 95.7652 ]\n",
      " [81.96645 49.81993 32.05937 87.15542]\n",
      " [68.97283 39.58482 29.30642 81.59573]]\n",
      "testing model...\n",
      "Test batch number0\n",
      "Test batch number1\n",
      "Test batch number2\n",
      "Test batch number3\n",
      "Test batch number4\n",
      "Test batch number5\n",
      "Test batch number6\n",
      "Test batch number7\n",
      "Test batch number8\n",
      "Test batch number9\n",
      "val scores: mean is 3.7309440626454125 , std is 0.0004077675137692294\n",
      "::: training epoch id 1 :: --- val mean=3.7309440626454125 , std=0.0004077675137692294 ; --- best val mean=3.7309440626454125 , std=0.00040039023999013045 \n",
      "Train batch number0\n",
      "Train batch number1\n",
      "Train batch number2\n",
      "Train batch number3\n",
      "Train batch number4\n",
      "[[ 89.77769  57.54885  32.13832  90.52684]\n",
      " [ 80.73882  49.1177   31.52879  92.33384]\n",
      " [ 67.52002  39.78648  27.65059  82.95004]\n",
      " [ 81.09776  53.80761  27.20522  84.92177]\n",
      " [ 76.61503  42.97294  33.53555 106.53922]]\n",
      "testing model...\n",
      "Test batch number0\n",
      "Test batch number1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-2b2b81e78f62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mexp_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrnscores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0mvalscores_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalscores_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmolsup_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_num_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mvalaggr_mean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalscores_mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch_dl4chem-geometry/test.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, test_loader, molsup_val, val_num_samples, debug, savepred_path, savepermol, refine_steps, useFF)\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPX_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproximity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msavepred_path\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/rdenv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch_dl4chem-geometry/CoordAE.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, nodes, masks, edges, proximity, pos)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;31m# used for iterative refinement of predictions ; det stands for deterministic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mX_edge_wgt_det\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_nn_post_x_det\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#[batch_size, n_max, n_max, dim_h, dim_h]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0mX_hidden_det\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmpnn_post_x_det\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_edge_wgt_det\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostZ_mu\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnodes_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mX_pred_det\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatent_nn_post_x_det\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_hidden_det\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/rdenv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch_dl4chem-geometry/CoordAE.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, edges)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0memb1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFC_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medges_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0memb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFC_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0medges_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=5, suppress=True)\n",
    "\n",
    "# training step\n",
    "# add model.train() optimizer zerograd ...\n",
    "\n",
    "save_path = 'savepreddir'\n",
    "train_event_path = None\n",
    "valid_event_path = None\n",
    "log_train_steps=100\n",
    "tm_trn=None\n",
    "tm_val=None\n",
    "w_reg=1e-3\n",
    "debug=False\n",
    "exp=None # Experiment\n",
    "\n",
    "model = CoordAE(n_max, dim_node, dim_edge, hidden_node_dim, dim_f, batch_size, \\\n",
    "                    mpnn_steps=mpnn_steps, alignment_type=alignment_type, tol=tol,\\\n",
    "                    use_X=use_X, use_R=use_R, seed=seed, \\\n",
    "                    refine_steps=refine_steps, refine_mom=refine_mom)\n",
    "\n",
    "kldloss = KLDLoss()\n",
    "optimizer = Adam(model.parameters(), lr=3e-4)\n",
    "msd_scorer = MSDScorer('default')\n",
    "\n",
    "if exp is not None:\n",
    "    data_path = exp.get_data_path(exp.name, exp.version)\n",
    "    save_path = os.path.join(data_path, 'checkpoints/model.ckpt')\n",
    "    event_path = os.path.join(data_path, 'event/')\n",
    "    print(save_path, flush=True)\n",
    "    print(event_path, flush=True)\n",
    "    \n",
    "if not debug:\n",
    "    train_summary_writer = SummaryWriter(train_event_path)\n",
    "    valid_summary_writer = SummaryWriter(valid_event_path)\n",
    "\n",
    "# training\n",
    "print('::: start training')\n",
    "num_epochs = 5\n",
    "valaggr_mean = np.zeros(num_epochs)\n",
    "valaggr_std = np.zeros(num_epochs)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    model.train()\n",
    "    trnscores = np.zeros((len(train_dataloader), 4))\n",
    "    \n",
    "    for batch_idx, batch in enumerate(train_dataloader) :\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        print('Train batch number' + str(batch_idx))\n",
    "        \n",
    "        # batch to be created\n",
    "        nodes, masks, edges, proximity, pos = batch\n",
    "        masks = masks.unsqueeze(-1) # because dataloader squeezes the mask Tensor\n",
    "        \n",
    "        postZ_mu, postZ_lsgms, priorZ_mu, priorZ_lsgms, X_pred, PX_pred = model(nodes, masks, edges, proximity, pos)\n",
    "    \n",
    "        cost_KLDZ = torch.mean(torch.sum(kldloss.loss(masks, postZ_mu, postZ_lsgms,  priorZ_mu, priorZ_lsgms), (1, 2))) # posterior | prior\n",
    "        cost_KLD0 = torch.mean(torch.sum(kldloss.loss(masks, priorZ_mu, priorZ_lsgms), (1, 2))) # prior | N(0,1)\n",
    "\n",
    "        cost_X = torch.mean(msd_scorer.score(X_pred, pos, masks))\n",
    "\n",
    "        cost_op = cost_X + cost_KLDZ + w_reg * cost_KLD0\n",
    "        \n",
    "        if debug:\n",
    "            print(batch_idx, n_batch)\n",
    "            print(trnresult, flush=True)\n",
    "\n",
    "        # log results\n",
    "        curr_iter = epoch * len(train_dataloader) + batch_idx\n",
    "\n",
    "        if not debug:\n",
    "            if curr_iter % log_train_steps == 0:\n",
    "                train_summary_writer.add_scalar(\"train/cost_op\", cost_op, curr_iter)\n",
    "                train_summary_writer.add_scalar(\"train/cost_X\", cost_X, curr_iter)\n",
    "                train_summary_writer.add_scalar(\"train/cost_KLDZ\", cost_KLDZ, curr_iter)\n",
    "                train_summary_writer.add_scalar(\"train/cost_KLD0\", cost_KLD0, curr_iter)\n",
    "\n",
    "        trnresult = np.array([cost_op.detach(), cost_X.detach(), cost_KLDZ.detach(), cost_KLD0.detach()])\n",
    "        assert np.sum(np.isnan(trnresult)) == 0\n",
    "        trnscores[batch_idx,:] = trnresult\n",
    "        \n",
    "        cost_op.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(trnscores)\n",
    "    \n",
    "    exp_dict = {}\n",
    "    if exp is not None:\n",
    "        exp_dict['training epoch id'] = epoch\n",
    "        exp_dict['train_score'] = np.mean(trnscores,0)\n",
    "\n",
    "    valscores_mean, valscores_std = test(model, val_dataloader, molsup_val, val_num_samples, debug=debug)\n",
    "\n",
    "    valaggr_mean[epoch] = valscores_mean\n",
    "    valaggr_std[epoch] = valscores_std\n",
    "\n",
    "    if not debug:\n",
    "        valid_summary_writer.add_scalar(\"val/valscores_mean\", valscores_mean, epoch)\n",
    "        valid_summary_writer.add_scalar(\"val/min_valscores_mean\", np.min(valaggr_mean[0:epoch+1]), epoch)\n",
    "        valid_summary_writer.add_scalar(\"val/valscores_std\", valscores_std, epoch)\n",
    "        valid_summary_writer.add_scalar(\"val/min_valscores_std\", np.min(valaggr_std[0:epoch+1]), epoch)\n",
    "\n",
    "    print ('::: training epoch id {} :: --- val mean={} , std={} ; --- best val mean={} , std={} '.format(\\\n",
    "            epoch, valscores_mean, valscores_std, np.min(valaggr_mean[0:epoch+1]), np.min(valaggr_std[0:epoch+1])))\n",
    "    \n",
    "#     if exp is not None:\n",
    "#         exp_dict['val mean'] = valscores_mean\n",
    "#         exp_dict['std'] = valscores_std\n",
    "#         exp_dict['best val mean'] = np.min(valaggr_mean[0:epoch+1])\n",
    "#         exp_dict['std of best val mean'] = np.min(valaggr_std[0:epoch+1])\n",
    "#         exp.log(exp_dict)\n",
    "#         exp.save()\n",
    "\n",
    "        \n",
    "    \n",
    "#     # keep track of the best model as well in the separate checkpoint\n",
    "#     # it is done by copying the checkpoint\n",
    "#     if valaggr_mean[epoch] == np.min(valaggr_mean[0:epoch+1]) and not debug:\n",
    "#         for ckpt_f in glob.glob(save_path + '*'):\n",
    "#             model_name_split = ckpt_f.split('/')\n",
    "#             model_path = '/'.join(model_name_split[:-1])\n",
    "#             model_name = model_name_split[-1]\n",
    "#             best_model_name = model_name.split('.')[0] + '_best.' + '.'.join(model_name.split('.')[1:])\n",
    "#             full_best_model_path = os.path.join(model_path, best_model_name)\n",
    "#             full_model_path = ckpt_f\n",
    "#             shutil.copyfile(full_model_path, full_best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.test(D1_tst, D2_tst, D3_tst, D4_tst, D5_tst, molsup_tst, \\\n",
    "                    load_path=args.loaddir, tm_v=tm_tst, debug=args.debug, \\\n",
    "                    savepred_path=args.savepreddir, savepermol=args.savepermol, useFF=args.useFF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
