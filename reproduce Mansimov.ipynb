{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pickle as pkl\n",
    "import scipy.sparse as sparse\n",
    "import copy\n",
    "import shutil\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from test_tube import Experiment\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "from CoordAE import CoordAE\n",
    "from MSDScorer import MSDScorer\n",
    "from KLDLoss import KLDLoss\n",
    "from data_utils import CODDataset, BlockDataLoader\n",
    "from test import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe85d757df0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 0\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handled in args parse for a py script version\n",
    "\n",
    "n_max = 50\n",
    "dim_node = 35\n",
    "dim_edge = 10\n",
    "nval = 3000\n",
    "ntst = 3000\n",
    "hidden_node_dim = 50\n",
    "dim_f = 100\n",
    "batch_size = 20\n",
    "val_num_samples = 10\n",
    "model_name = 'dl4chem'\n",
    "savepermol = True\n",
    "savepreddir = 'savepreddir'\n",
    "use_val = True\n",
    "mpnn_steps = 5\n",
    "alignment_type = 'kabsch'\n",
    "tol = 1e-5\n",
    "use_X=False\n",
    "use_R=True\n",
    "seed=1334\n",
    "refine_steps=0\n",
    "refine_mom=0.99\n",
    "debug = False\n",
    "useFF = False\n",
    "w_reg = 1e-5\n",
    "log_train_steps=100\n",
    "\n",
    "\n",
    "data_dir = 'data/'\n",
    "dataset = 'COD'\n",
    "COD_molset_50_path = data_dir + 'COD_molset_50.p'  \n",
    "COD_molvec_50_path = data_dir + 'COD_molvec_50.p'\n",
    "\n",
    "# create directories to store results\n",
    "\n",
    "ckptdir = './checkpoints/'\n",
    "if not os.path.exists(ckptdir):\n",
    "    os.makedirs(ckptdir)\n",
    "    \n",
    "eventdir = './events/'\n",
    "train_eventdir = eventdir.split('/')\n",
    "train_eventdir.insert(-1, 'train')\n",
    "train_eventdir = '/'.join(train_eventdir)\n",
    "\n",
    "valid_eventdir = eventdir.split('/')\n",
    "valid_eventdir.insert(-1, 'valid')\n",
    "valid_eventdir = '/'.join(valid_eventdir)\n",
    "\n",
    "if not os.path.exists(train_eventdir):\n",
    "    os.makedirs(train_eventdir)\n",
    "if not os.path.exists(valid_eventdir):\n",
    "    os.makedirs(valid_eventdir)\n",
    "\n",
    "save_path = os.path.join(ckptdir, model_name + '_model.ckpt')\n",
    "\n",
    "molvec_fname = data_dir + dataset + '_molvec_'+str(n_max)+'.p'\n",
    "molset_fname = data_dir + dataset + '_molset_'+str(n_max)+'.p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "nodes_fname = data_dir + dataset + '_nodes_'+str(n_max)+'.p'\n",
    "D1 = pkl.load(open(nodes_fname,'rb'))\n",
    "\n",
    "masks_fname = data_dir + dataset + '_masks_'+str(n_max)+'.p'\n",
    "D2 = pkl.load(open(masks_fname,'rb'))\n",
    "\n",
    "edges_fname = data_dir + dataset + '_edges_'+str(n_max)+'.p'\n",
    "D3 = pkl.load(open(edges_fname,'rb'))\n",
    "\n",
    "dist_mats_fname = data_dir + dataset + '_dist_mats_'+str(n_max)+'.p'\n",
    "D4 = pkl.load(open(dist_mats_fname,'rb'))\n",
    "\n",
    "positions_fname = data_dir + dataset + '_positions_'+str(n_max)+'.p'\n",
    "D5 = pkl.load(open(positions_fname,'rb'))\n",
    "\n",
    "#[D1, D2, D3, D4, D5] = pkl.load(open(molvec_fname,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::: num train samples is \n",
      "(60663, 50, 35) (60663, 50, 1)\n"
     ]
    }
   ],
   "source": [
    "D1 = D1.todense()\n",
    "D2 = D2.todense()\n",
    "D3 = D3.todense()\n",
    "\n",
    "ntrn = len(D5)-nval-ntst\n",
    "\n",
    "[molsup, molsmi] = pkl.load(open(molset_fname,'rb'))\n",
    "\n",
    "D1_trn = D1[:ntrn]\n",
    "D2_trn = D2[:ntrn]\n",
    "D3_trn = D3[:ntrn]\n",
    "D4_trn = D4[:ntrn]\n",
    "D5_trn = D5[:ntrn]\n",
    "molsup_trn = molsup[:ntrn]\n",
    "D1_val = D1[ntrn:ntrn+nval]\n",
    "D2_val = D2[ntrn:ntrn+nval]\n",
    "D3_val = D3[ntrn:ntrn+nval]\n",
    "D4_val = D4[ntrn:ntrn+nval]\n",
    "D5_val = D5[ntrn:ntrn+nval]\n",
    "molsup_val = molsup[ntrn:ntrn+nval]\n",
    "D1_tst = D1[ntrn+nval:ntrn+nval+ntst]\n",
    "D2_tst = D2[ntrn+nval:ntrn+nval+ntst]\n",
    "D3_tst = D3[ntrn+nval:ntrn+nval+ntst]\n",
    "D4_tst = D4[ntrn+nval:ntrn+nval+ntst]\n",
    "D5_tst = D5[ntrn+nval:ntrn+nval+ntst]\n",
    "molsup_tst = molsup[ntrn+nval:ntrn+nval+ntst]\n",
    "print ('::: num train samples is ')\n",
    "print(D1_trn.shape, D3_trn.shape)\n",
    "\n",
    "tm_trn, tm_val, tm_tst = None, None, None\n",
    "\n",
    "del D1, D2, D3, D4, D5, molsup\n",
    "\n",
    "if savepermol:\n",
    "    savepreddir = os.path.join(savepreddir, dataset, \"_val_\" if use_val else \"_test_\")\n",
    "    if not os.path.exists(savepreddir):\n",
    "        os.makedirs(savepreddir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CODDataset(D1_trn, D2_trn, D3_trn, D4_trn, D5_trn)\n",
    "val_dataset = CODDataset(D1_val, D2_val, D3_val, D4_val, D5_val)\n",
    "test_dataset = CODDataset(D1_tst, D2_tst, D3_tst, D4_tst, D5_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Subset(train_dataset, range(100))\n",
    "val_dataset = Subset(val_dataset, range(100))\n",
    "test_dataset = Subset(test_dataset, range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = BlockDataLoader(train_dataset, batch_size, block_size=40)\n",
    "val_num_samples = 2\n",
    "val_batch_size = batch_size // val_num_samples\n",
    "val_dataloader = BlockDataLoader(val_dataset, val_batch_size, block_size=40)\n",
    "test_dataloader = BlockDataLoader(test_dataset, batch_size, block_size=40)\n",
    "\n",
    "# train_dataloader = BlockDataLoader(train_dataset, batch_size)\n",
    "# val_dataloader = BlockDataLoader(val_dataset, batch_size)\n",
    "# test_dataloader = BlockDataLoader(test_dataset, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60663, 50, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D3_trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::: start training\n",
      "Train batch number0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-e3ac090c0ba6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# because dataloader squeezes the mask Tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mpostZ_mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostZ_lsgms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpriorZ_mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpriorZ_lsgms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPX_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproximity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mcost_KLDZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkldloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostZ_mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostZ_lsgms\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mpriorZ_mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpriorZ_lsgms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# posterior | prior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dlenv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/baillifb/DATA/Ben/Documents/science/pytorch_dl4chem-geometry/CoordAE.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, nodes, masks, edges, proximity, pos)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;31m# Isn't there a better way to add n_atom in edge features ?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0medge_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtiled_n_atom\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (batch_size, n_max, nmax, dim_edge + 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 3)"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=5, suppress=True)\n",
    "\n",
    "# training step\n",
    "# add model.train() optimizer zerograd ...\n",
    "\n",
    "save_path = 'savepreddir'\n",
    "train_event_path = None\n",
    "valid_event_path = None\n",
    "log_train_steps=100\n",
    "tm_trn=None\n",
    "tm_val=None\n",
    "w_reg=1e-3\n",
    "debug=False\n",
    "exp=None # Experiment\n",
    "\n",
    "model = CoordAE(n_max, dim_node, dim_edge, hidden_node_dim, dim_f, batch_size, \\\n",
    "                    mpnn_steps=mpnn_steps, alignment_type=alignment_type, tol=tol,\\\n",
    "                    use_X=use_X, use_R=use_R, seed=seed, \\\n",
    "                    refine_steps=refine_steps, refine_mom=refine_mom)\n",
    "\n",
    "kldloss = KLDLoss()\n",
    "optimizer = Adam(model.parameters(), lr=3e-4)\n",
    "msd_scorer = MSDScorer('default')\n",
    "\n",
    "if exp is not None:\n",
    "    data_path = exp.get_data_path(exp.name, exp.version)\n",
    "    save_path = os.path.join(data_path, 'checkpoints/model.ckpt')\n",
    "    event_path = os.path.join(data_path, 'event/')\n",
    "    print(save_path, flush=True)\n",
    "    print(event_path, flush=True)\n",
    "    \n",
    "if not debug:\n",
    "    train_summary_writer = SummaryWriter(train_event_path)\n",
    "    valid_summary_writer = SummaryWriter(valid_event_path)\n",
    "\n",
    "# training\n",
    "print('::: start training')\n",
    "num_epochs = 3\n",
    "valaggr_mean = np.zeros(num_epochs)\n",
    "valaggr_std = np.zeros(num_epochs)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    trnscores = np.zeros((len(train_dataloader), 4))\n",
    "    \n",
    "    for batch_idx, batch in enumerate(train_dataloader) :\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        print('Train batch number' + str(batch_idx))\n",
    "        \n",
    "        # batch to be created\n",
    "        nodes, masks, edges, proximity, pos = batch\n",
    "        masks = masks.unsqueeze(-1) # because dataloader squeezes the mask Tensor\n",
    "        \n",
    "        postZ_mu, postZ_lsgms, priorZ_mu, priorZ_lsgms, X_pred, PX_pred = model(nodes, masks, edges, proximity, pos)\n",
    "    \n",
    "        cost_KLDZ = torch.mean(torch.sum(kldloss.loss(masks, postZ_mu, postZ_lsgms,  priorZ_mu, priorZ_lsgms), (1, 2))) # posterior | prior\n",
    "        cost_KLD0 = torch.mean(torch.sum(kldloss.loss(masks, priorZ_mu, priorZ_lsgms), (1, 2))) # prior | N(0,1)\n",
    "\n",
    "        cost_X = torch.mean(msd_scorer.score(X_pred, pos, masks))\n",
    "\n",
    "        cost_op = cost_X + cost_KLDZ + w_reg * cost_KLD0\n",
    "        loss = -cost_op\n",
    "\n",
    "        if debug:\n",
    "            print(batch_idx, n_batch)\n",
    "            print(trnresult, flush=True)\n",
    "\n",
    "        # log results\n",
    "        curr_iter = epoch * len(train_dataloader) + batch_idx\n",
    "\n",
    "        if not debug:\n",
    "            if curr_iter % log_train_steps == 0:\n",
    "                train_summary_writer.add_scalar(\"train/cost_op\", cost_op, curr_iter)\n",
    "                train_summary_writer.add_scalar(\"train/cost_X\", cost_X, curr_iter)\n",
    "                train_summary_writer.add_scalar(\"train/cost_KLDZ\", cost_KLDZ, curr_iter)\n",
    "                train_summary_writer.add_scalar(\"train/cost_KLD0\", cost_KLD0, curr_iter)\n",
    "\n",
    "        trnresult = np.array([cost_op.detach(), cost_X.detach(), cost_KLDZ.detach(), cost_KLD0.detach()])\n",
    "        assert np.sum(np.isnan(trnresult)) == 0\n",
    "        trnscores[batch_idx,:] = trnresult\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(np.mean(trnscores,0), flush=True)\n",
    "    \n",
    "    exp_dict = {}\n",
    "    if exp is not None:\n",
    "        exp_dict['training epoch id'] = epoch\n",
    "        exp_dict['train_score'] = np.mean(trnscores,0)\n",
    "\n",
    "    valscores_mean, valscores_std = test(model, val_dataloader, molsup_val, val_num_samples, debug=debug)\n",
    "\n",
    "    valaggr_mean[epoch] = valscores_mean\n",
    "    valaggr_std[epoch] = valscores_std\n",
    "\n",
    "    if not debug:\n",
    "        valid_summary_writer.add_scalar(\"val/valscores_mean\", valscores_mean, epoch)\n",
    "        valid_summary_writer.add_scalar(\"val/min_valscores_mean\", np.min(valaggr_mean[0:epoch+1]), epoch)\n",
    "        valid_summary_writer.add_scalar(\"val/valscores_std\", valscores_std, epoch)\n",
    "        valid_summary_writer.add_scalar(\"val/min_valscores_std\", np.min(valaggr_std[0:epoch+1]), epoch)\n",
    "\n",
    "    print ('::: training epoch id {} :: --- val mean={} , std={} ; --- best val mean={} , std={} '.format(\\\n",
    "            epoch, valscores_mean, valscores_std, np.min(valaggr_mean[0:epoch+1]), np.min(valaggr_std[0:epoch+1])))\n",
    "    \n",
    "    if exp is not None:\n",
    "        exp_dict['val mean'] = valscores_mean\n",
    "        exp_dict['std'] = valscores_std\n",
    "        exp_dict['best val mean'] = np.min(valaggr_mean[0:epoch+1])\n",
    "        exp_dict['std of best val mean'] = np.min(valaggr_std[0:epoch+1])\n",
    "        exp.log(exp_dict)\n",
    "        exp.save()\n",
    "\n",
    "        \n",
    "    \n",
    "#     # keep track of the best model as well in the separate checkpoint\n",
    "#     # it is done by copying the checkpoint\n",
    "#     if valaggr_mean[epoch] == np.min(valaggr_mean[0:epoch+1]) and not debug:\n",
    "#         for ckpt_f in glob.glob(save_path + '*'):\n",
    "#             model_name_split = ckpt_f.split('/')\n",
    "#             model_path = '/'.join(model_name_split[:-1])\n",
    "#             model_name = model_name_split[-1]\n",
    "#             best_model_name = model_name.split('.')[0] + '_best.' + '.'.join(model_name.split('.')[1:])\n",
    "#             full_best_model_path = os.path.join(model_path, best_model_name)\n",
    "#             full_model_path = ckpt_f\n",
    "#             shutil.copyfile(full_model_path, full_best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.test(D1_tst, D2_tst, D3_tst, D4_tst, D5_tst, molsup_tst, \\\n",
    "                    load_path=args.loaddir, tm_v=tm_tst, debug=args.debug, \\\n",
    "                    savepred_path=args.savepreddir, savepermol=args.savepermol, useFF=args.useFF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
